---
title: "Evaluating Solution Quality and Problem Difficulty using Code Metrics"
author: "Gurpreet Singh"
date: '`r Sys.Date()`'
output:
  ioslides_presentation:
    widescreen: true
    df_print: paged
    css: "./ioslides.css"
---

---
# Prof wants these things:
# Explain Problem
# Explain dataset with example of single entry
# Explain potential datascience methods
# Ability to answer questions about data
# Keep it under 10 mins
# 5% of mark
---

```{r echo=FALSE, message=FALSE}
library(RColorBrewer)
library(forcats)
library(ggplot2)
library(SnowballC)
library(wordcloud)
library(tm)
```

## Background Info

### Code-Compile-Evaluate Websites
- HackerRank
- CodeEval
- CodeChef
- CoderBytes
- TopCoder
- ![code quality](code_quality.png)

## Problem

- Programming technologies pop up and disappear faster than textbooks can be printed

- Traditional teaching/testing methods being replaced by 'just in time' techniques

- Researchers and students are learning bad code style by only focusing on getting to the solution

- Interviewers are using online websites to judge code samples that don't consider many important aspects of programming.

## Significance

- Code-Compile-Evaluate loop websites have a large influence on the community

- Programming challenge websites could use this data to better score their puzzles

- HR-Level interviewers could better evaluate candidates

## Project Goals

- Identify which types of questions influence good/bad code style

- Discover the impact of good/bad code style on completion rates

- Make a conclusion about about the effects of factoring in code style as an evaluation measure in regards to accuracy.

- Future plans: Create a website that evaluates users solely based on how well they follow the style guide if their solution is correct
 
# Exploring the Dataset 
time for some R fun

## Questions Data {.smaller}

```{r}
questions <- read.csv("data/questions.csv")
str(questions)
head(questions, 2)
```

## Questions Data {.smaller}
```{r}
questions$level = fct_infreq(questions$level)
qplot(level, fill = level, data = questions, geom = "bar")
```

## Solution Data {.smaller}

```{r}
solutions <- read.csv("data/solutions.csv")
str(solutions)
head(solutions, 2)
```

## Solution Data {.smaller}

```{r}
runtimeErrors <- c("runtime error(SIGABRT)", "runtime error(SIGFPE)", "runtime error(OTHER)", "runtime error(NZEC)", "runtime error(SIGXFSZ)", "runtime error(SIGSEGV)", "")
solutions$Status <- solutions$Status %>% fct_collapse("runtime errors" = runtimeErrors)
solutions$Status = fct_infreq(solutions$Status)
qplot(Status, fill = Status, data = solutions, geom = "bar") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Solution Data {.smaller}

```{r}
solutions$Language = fct_infreq(solutions$Language)
qplot(Language, fill = Language, data = solutions, geom = "bar") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + guides(fill=FALSE)
```

## Code Data {.smaller}

```{r}
code <- read.csv("data/first.csv")
str(code)
head(code, 1)
```

# Plan for Analysis

## Feature Creation
- Link 3 Datasets together (Question/Solution/Code)

- Process code samples into a value that accurately represents it's quality
  -   Only 3 major languages
  -   May need to separate dataset into languages to get fair comparison

- Process the question statement using NLP into a value that represents difficulty.
- Develop categories of questions using NLP library

## Planned Analysis

### Classifier for acceptance 

- Create a model using logistic regression on the generated code quality feature 
- Use that as a classifier that will predict if a solution's "Status" (approved/declined)

### Visualizations

- Correlation matrix showing the correlation between solution features and generated code quality feature
- Scatterplot between NLP derived difficulty and CodeChef difficulty.

## Current Issues

```{r}

words <- Corpus(VectorSource(questions$statement))
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
words <- tm_map(words, toSpace, "/")
words <- tm_map(words, toSpace, "@")
words <- tm_map(words, toSpace, "\\|")
words <- tm_map(words, content_transformer(tolower))
words <- tm_map(words, removeWords, stopwords("english"))
words <- tm_map(words, removeNumbers)
words <- tm_map(words, removePunctuation)
words <- tm_map(words, stripWhitespace)
words <- tm_map(words, stemDocument)
v <- sort(rowSums(as.matrix(TermDocumentMatrix(words))),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
```

## QUESTIONS? {.smaller}
```{r}
wordcloud(words = d$word, freq = d$freq, min.freq = 1, max.words=150, random.order=FALSE)
```
